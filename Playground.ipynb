{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "ec94eed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import (alexnet,\n",
    "                                AlexNet_Weights,\n",
    "                                resnet18,\n",
    "                                ResNet18_Weights,\n",
    "                                ResNet)\n",
    "\n",
    "\n",
    "model = alexnet(weights=AlexNet_Weights.DEFAULT)\n",
    "encoder  = model.features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "3485090c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralImageCompressor(nn.Module):\n",
    "    def __init__(self,\n",
    "                 encoder: nn.Module,\n",
    "                 decoder: nn.Module,\n",
    "                 normalising_activation: nn.Module = nn.Sigmoid(),\n",
    "                 B: int = 1):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.normalising_activation = normalising_activation\n",
    "        self.B = B\n",
    "            \n",
    "    def _get_quantization_error(self, shape: Tuple[int, ...]):\n",
    "        mean = torch.full(shape, -0.5)\n",
    "        std = torch.full(shape, 0.5)\n",
    "        return 0.5**self.B * torch.normal(mean = mean, std = std)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.encoder(x)\n",
    "        out = self.normalising_activation(out)\n",
    "        out += self._get_quantization_error(out.shape)\n",
    "        out = self.decoder(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "d72de04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoencoderAlexNet(NeuralImageCompressor):\n",
    "    def __init__(self, B: int = 1, normalising_activation: nn.Module = nn.Sigmoid()):\n",
    "        encoder = alexnet(weights=AlexNet_Weights.DEFAULT).features\n",
    "        decoder = self._get_decoder(encoder)\n",
    "        super().__init__(encoder, decoder, normalising_activation, B)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _get_decoder(encoder: nn.Sequential):\n",
    "        decoder_modules = []\n",
    "\n",
    "        for module in reversed(encoder):\n",
    "            if isinstance(module, nn.Conv2d):\n",
    "                trans_conv = nn.ConvTranspose2d(\n",
    "                    in_channels=module.out_channels,\n",
    "                    out_channels=module.in_channels,\n",
    "                    kernel_size=module.kernel_size,\n",
    "                    stride=module.stride,\n",
    "                    padding=module.padding\n",
    "                )\n",
    "                decoder_modules.append(trans_conv)\n",
    "            elif isinstance(module, nn.ReLU):\n",
    "                decoder_modules.append(nn.ReLU(inplace=True))\n",
    "            elif isinstance(module, nn.MaxPool2d):\n",
    "                # We can use MaxUnpool if we're going to save MaxPool indicies\n",
    "                # unpool = nn.MaxUnpool2d(\n",
    "                #     kernel_size=module.kernel_size,\n",
    "                #     stride=module.stride,\n",
    "                #     padding=module.padding\n",
    "                # )\n",
    "                upsample = nn.Upsample(\n",
    "                    scale_factor=2,\n",
    "                    mode='nearest'\n",
    "                )\n",
    "                decoder_modules.append(upsample)\n",
    "            else:\n",
    "                raise ValueError(f\"unexpected module {module}\")\n",
    "            \n",
    "        decoder = nn.Sequential(*decoder_modules)\n",
    "        return decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8922d4fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "78802aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 227, 227])"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alexnet_autoencoder = AutoencoderAlexNet()\n",
    "\n",
    "test_image = torch.rand(3, 256, 256)\n",
    "\n",
    "alexnet_autoencoder(test_image.unsqueeze(0)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e6f639",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41a25f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "70aca100",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoderResNet(NeuralImageCompressor):\n",
    "    def __init__(self, resnet: ResNet, decoder: nn.Module,\n",
    "                 normalising_activation: nn.Module = nn.Sigmoid(), B: int = 1):\n",
    "        encoder = self._get_resnet_encoder(resnet)\n",
    "        super().__init__(encoder, decoder, normalising_activation, B)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _get_resnet_encoder(resnet: ResNet):\n",
    "        return nn.Sequential(\n",
    "            resnet.conv1,\n",
    "            resnet.bn1,\n",
    "            resnet.relu,\n",
    "            resnet.maxpool,\n",
    "            resnet.layer1,\n",
    "            resnet.layer2,\n",
    "            resnet.layer3,\n",
    "            resnet.layer4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "a5b77e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_8x_upsample_constructor(in_chan_num):\n",
    "    out_chan_nums = [512, 256, 128, 64, 3]\n",
    "\n",
    "    decoder_modules = []\n",
    "\n",
    "    for out_chan_num in out_chan_nums:\n",
    "        decoder_modules.append(\n",
    "            nn.Sequential(\n",
    "                nn.Upsample(\n",
    "                    scale_factor=2,\n",
    "                    mode='nearest'\n",
    "                ),\n",
    "                nn.Conv2d(in_channels=in_chan_num, out_channels=out_chan_num, kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        )\n",
    "\n",
    "        in_chan_num = out_chan_num\n",
    "    \n",
    "    return nn.Sequential(*decoder_modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bf021a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "fbcd99fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_encoder_constructor(resnet):\n",
    "    return nn.Sequential(\n",
    "        resnet.conv1,\n",
    "        resnet.bn1,\n",
    "        resnet.relu,\n",
    "        resnet.maxpool,\n",
    "        resnet.layer1,\n",
    "        resnet.layer2,\n",
    "        resnet.layer3,\n",
    "        resnet.layer4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "8fd2b88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_encoder = resnet_encoder_constructor(resnet18(weights=ResNet18_Weights.DEFAULT))\n",
    "\n",
    "decoder_in_channels = 512\n",
    "\n",
    "decoder_8x_upsample = decoder_8x_upsample_constructor(decoder_in_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca29a1b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "e7657e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_autoencoder = NeuralImageCompressor(resnet_encoder, decoder_8x_upsample, nn.Sigmoid(), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "a73a919f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 64, 64])"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image = torch.rand(3, 64, 64)\n",
    "resnet_autoencoder(test_image.unsqueeze(0)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d23a61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e042875",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = torch.rand(3, 64, 64)\n",
    "resnet_autoencoder(test_image.unsqueeze(0)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0b5ebc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "bb85289f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_output_channels_of_resnet_encoder(resnet_encoder):\n",
    "#     num_out_channels = None\n",
    "#     for module in reversed(resnet_encoder[-1][-1]):\n",
    "#         if isinstance(module, nn.Conv2d):\n",
    "#             last_conv = module\n",
    "#             num_out_channels = module.out_channels\n",
    "#     return num_out_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "fae3f8c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " ReLU(inplace=True),\n",
       " Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list(resnet_encoder[-1][-1].children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9031197e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "5637c064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size: torch.Size([1, 3, 16, 16])\n",
      "Output size: torch.Size([1, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "# Upsampling with transposed convolution\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "input_size = (3, 16, 16)  # Input tensor size (channels, height, width)\n",
    "output_channels = 3  # Number of output channels\n",
    "kernel_size = 4  # Kernel size in the transpose convolution\n",
    "stride = 2  # Stride in the transpose convolution\n",
    "padding = 1  # Padding in the transpose convolution\n",
    "\n",
    "# Create a random input tensor\n",
    "input_tensor = torch.randn(1, *input_size)\n",
    "\n",
    "# Define the transpose convolution layer\n",
    "trans_conv = nn.ConvTranspose2d(\n",
    "    in_channels=input_size[0],\n",
    "    out_channels=output_channels,\n",
    "    kernel_size=kernel_size,\n",
    "    stride=stride,\n",
    "    padding=padding\n",
    ")\n",
    "\n",
    "# Apply the transpose convolution to the input tensor\n",
    "output_tensor = trans_conv(input_tensor)\n",
    "\n",
    "# Check the size of the output tensor\n",
    "print(\"Input size:\", input_tensor.size())\n",
    "print(\"Output size:\", output_tensor.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b98fe0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
